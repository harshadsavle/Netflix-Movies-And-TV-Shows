{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOvTErbGXZROtUUEjEoYuh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshadsavle/Netflix-Movies-And-TV-Shows/blob/main/Netflix_Movies_And_TV_Shows_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**"
      ],
      "metadata": {
        "id": "dpmJSnfFAGZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming serviceâ€™s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset."
      ],
      "metadata": {
        "id": "cA9cvfwjAIwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **In this project, we are required to do**\n",
        "1. Exploratory Data Analysis \n",
        "\n",
        "2. Understanding what type content is available in different countries\n",
        "\n",
        "3. Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4. Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "t7ipFTv4Ayyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Information**\n",
        "\n",
        "* **Show_id** : Unique ID for every Movie / Tv Show\n",
        "\n",
        "* **Type** : Identifier - A Movie or TV Show\n",
        "\n",
        "* **Title** : Title of the Movie / Tv Show\n",
        "\n",
        "* **Director*** : Director of the Movie\n",
        "\n",
        "* **Cast** : Actors involved in the movie / show\n",
        "\n",
        "* **Country** : Country where the movie / show was produced\n",
        "\n",
        "* **Date_added** : Date it was added on Netflix\n",
        "\n",
        "* **Release_year** : Actual Releaseyear of the movie / show\n",
        "\n",
        "* **Rating** : TV Rating of the movie / show\n",
        "\n",
        "* **Duration** : Total Duration - in minutes or number of seasons\n",
        "\n",
        "* **Listed_in** : Genere\n",
        "\n",
        "* **Description**: The Summary description\n"
      ],
      "metadata": {
        "id": "tqChqxFCBReo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Libraries**"
      ],
      "metadata": {
        "id": "FnMGm_kvBnAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import spacy\n",
        "import sklearn\n",
        "import en_core_web_sm\n",
        "\n",
        "from nltk.corpus import stopwords  #stopwords\n",
        "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
        "!pip install nltk\n",
        "import nltk \n",
        "!python3 -c \"import nltk; nltk.download('all')\"\n",
        "\n",
        "#stop-words\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# for named entity recognition (NER)\n",
        "from nltk import ne_chunk\n",
        "\n",
        "# vectorizers for creating the document-term-matrix (DTM)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "\n",
        "# Importing libraries for clustering\n",
        "import matplotlib.cm as cm\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "#from scipy.cluster.hierarchy import linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "D1qOsOK1AGNO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}